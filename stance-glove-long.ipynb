{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64154fc6-e3b7-49c7-8d1f-e4f780c8a970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===-----------------------------------------------] 6.2% 23.4/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======-------------------------------------------] 15.5% 58.4/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============--------------------------------------] 24.7% 93.0/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================---------------------------------] 34.4% 129.5/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================----------------------------] 44.2% 166.1/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================------------------------] 53.9% 202.8/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============================-------------------] 63.3% 238.2/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================================--------------] 73.2% 275.3/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================================---------] 82.4% 309.8/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================================-----] 91.8% 345.4/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1253dd1b-660d-4dc6-a83d-2c28fbd0aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.dataset import DataSet\n",
    "from utils.generate_test_splits import generate_hold_out_split, read_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c129e9-81ce-41c7-9b39-f32ddbd45702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 49972\n",
      "Total bodies: 1683\n"
     ]
    }
   ],
   "source": [
    "d = DataSet()\n",
    "generate_hold_out_split(d)\n",
    "trainID = set(read_ids(\"training_ids.txt\", \"splits\"))\n",
    "valID = set(read_ids(\"hold_out_ids.txt\", \"splits\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d497e-a281-483e-919d-f7de19848b76",
   "metadata": {},
   "source": [
    "# Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddbb7929-7d1b-4d19-bb39-44616297ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_PER_ART = 20\n",
    "MAX_SENT_LEN = 30\n",
    "MAX_VOCAB = 20000\n",
    "VECTOR_SIZE = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde4bb2d-2708-47a7-973a-01e5fcc8a90d",
   "metadata": {},
   "source": [
    "# Set up training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b760b24-8e38-448d-907d-7af8f556427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stances = [stance for stance in d.stances if stance['Body ID'] in trainID]\n",
    "train_headlines = [stance['Headline'] for stance in train_stances]\n",
    "train_labels = [stance['Stance'] for stance in train_stances]\n",
    "train_body = [d.articles[stance['Body ID']] for stance in train_stances]\n",
    "\n",
    "val_stances = [stance for stance in d.stances if stance['Body ID'] in valID]\n",
    "val_headlines = [stance['Headline'] for stance in val_stances]\n",
    "val_labels = [stance['Stance'] for stance in val_stances]\n",
    "val_body = [d.articles[stance['Body ID']] for stance in val_stances]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65809091-a13b-4e7d-8a32-868df58d08fe",
   "metadata": {},
   "source": [
    "# Vectorization and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "181b27ca-c449-43e4-9590-f9adace47b60",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sw26wong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import tokenize\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "nltk.download('punkt')\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=MAX_VOCAB, output_sequence_length=MAX_SENT_LEN)\n",
    "vectorizer.adapt(train_body + train_headlines + val_body + val_headlines)\n",
    "\n",
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "642b1bba-9a57-4a8f-a10a-f6ac30213805",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tok_art = []\n",
    "for article in train_body:\n",
    "    sent_tok_art.append(tokenize.sent_tokenize(article))\n",
    "\n",
    "vsent_tok_art = []\n",
    "for article in val_body:\n",
    "    vsent_tok_art.append(tokenize.sent_tokenize(article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cdf08ca-4e0d-44e9-a7d2-a03ef9c51cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_body = np.zeros((len(train_stances), MAX_SENT_PER_ART, MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, article in enumerate(sent_tok_art):\n",
    "    for j, sentence in enumerate(article[:MAX_SENT_PER_ART]):\n",
    "        words = text_to_word_sequence(sentence)\n",
    "        for k, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "            X_train_body[i][j][k] = word_index.get(word, 1) # get else UNK\n",
    "\n",
    "X_train_head = np.zeros((len(train_stances), MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, headline in enumerate(train_headlines):\n",
    "    words = text_to_word_sequence(headline)\n",
    "    for j, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "        X_train_head[i][j] = word_index.get(word, 1)\n",
    "\n",
    "X_val_body = np.zeros((len(val_stances), MAX_SENT_PER_ART, MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, article in enumerate(vsent_tok_art):\n",
    "    for j, sentence in enumerate(article[:MAX_SENT_PER_ART]):\n",
    "        words = text_to_word_sequence(sentence)\n",
    "        for k, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "            X_val_body[i][j][k] = word_index.get(word, 1)\n",
    "\n",
    "X_val_head = np.zeros((len(val_stances), MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, headline in enumerate(val_headlines):\n",
    "    words = text_to_word_sequence(headline)\n",
    "    for j, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "        X_val_head[i][j] = word_index.get(word, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfd06aba-72ed-49c9-98b0-7bac194968ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.Series(train_labels)\n",
    "one_hot = pd.get_dummies(targets,sparse = True)\n",
    "one_hot_labels = np.asarray(one_hot)\n",
    "y_train = one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68403e35-626a-42d6-aa04-526e60dabd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.Series(val_labels)\n",
    "one_hot = pd.get_dummies(targets,sparse = True)\n",
    "one_hot_labels = np.asarray(one_hot)\n",
    "y_val = one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a72497-cdc8-4976-b67a-3fb3ef770c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['agree', 'disagree', 'discuss', 'unrelated']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a94ed6b-68b8-4b6e-8474-7fffd9e9a84a",
   "metadata": {},
   "source": [
    "# Create Embedding Matrix from Google word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3323e80-750a-4051-be75-c556b5707f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_index)\n",
    "embedding_matrix = np.zeros((vocab_size+1, VECTOR_SIZE))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        v = wv[word]\n",
    "        embedding_matrix[i] = v\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d0a0552-dbda-49d8-bd95-730048919fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del wv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2260b21a-ab1e-4839-895d-220f5f01943d",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1b4925d-7332-4af8-b50e-9e91114af8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM, TimeDistributed, Activation\n",
    "from keras.layers import Flatten, Permute, merge, Input\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,multiply,concatenate,Dropout\n",
    "from keras.layers import GRU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c6624ea-0440-4024-b8fd-12392d3683f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = VECTOR_SIZE\n",
    "\n",
    "sentence_input = Input(shape=(MAX_SENT_LEN,),dtype='int32')\n",
    "\n",
    "embedded_sequences = Embedding(output_dim = hidden_size, input_dim = vocab_size+1, input_length=MAX_SENT_LEN)(sentence_input)\n",
    "\n",
    "l_LSTM = Bidirectional(LSTM(hidden_size,return_sequences = True))(embedded_sequences)\n",
    "l_dense = TimeDistributed(Dense(hidden_size))(l_LSTM)\n",
    "l_dense = Flatten()(l_dense)\n",
    "sentEncoder = Model(sentence_input,l_dense)\n",
    "\n",
    "body_input = Input(shape=(MAX_SENT_PER_ART,MAX_SENT_LEN,),dtype = 'int32')\n",
    "\n",
    "body_encoder = TimeDistributed(sentEncoder)(body_input)\n",
    "\n",
    "l_LSTM_sent = Bidirectional(LSTM(hidden_size,return_sequences=True))(body_encoder)\n",
    "l_dense_sent = TimeDistributed(Dense(hidden_size))(l_LSTM_sent)\n",
    "l_dense_sent = Flatten()(l_dense_sent)\n",
    "\n",
    "heading_input = Input(shape = (MAX_SENT_LEN, ),dtype = 'int32')\n",
    "heading_embedded_sequences = Embedding(output_dim=hidden_size, input_dim=vocab_size+1, \\\n",
    "                                       input_length = (MAX_SENT_LEN,), \\\n",
    "                                      weights = [embedding_matrix])(heading_input)\n",
    "h_dense = Dense(hidden_size,activation='relu')(heading_embedded_sequences)\n",
    "h_flatten = Flatten()(h_dense)\n",
    "article_output = concatenate([l_dense_sent,h_flatten],name = 'concatenate_heading')\n",
    "\n",
    "news_vestor = Dense(hidden_size,activation = 'relu')(article_output)\n",
    "preds = Dense(4,activation = 'softmax')(news_vestor)\n",
    "model = Model([body_input,heading_input],[preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "961c4571-36a5-492c-af9b-3880370db565",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0b21d5f-2a72-4e29-bed1-02e6b8d2c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "631/631 [==============================] - 1756s 3s/step - loss: 0.5635 - categorical_accuracy: 0.7962 - val_loss: 0.7498 - val_categorical_accuracy: 0.6977\n",
      "Epoch 2/10\n",
      "631/631 [==============================] - 1473s 2s/step - loss: 0.2879 - categorical_accuracy: 0.8859 - val_loss: 0.6350 - val_categorical_accuracy: 0.7462\n",
      "Epoch 3/10\n",
      "631/631 [==============================] - 1402s 2s/step - loss: 0.1840 - categorical_accuracy: 0.9269 - val_loss: 0.6609 - val_categorical_accuracy: 0.7683\n",
      "Epoch 4/10\n",
      "631/631 [==============================] - 962s 2s/step - loss: 0.1380 - categorical_accuracy: 0.9473 - val_loss: 0.7606 - val_categorical_accuracy: 0.7933\n",
      "Epoch 5/10\n",
      "631/631 [==============================] - 846s 1s/step - loss: 0.0953 - categorical_accuracy: 0.9655 - val_loss: 0.9127 - val_categorical_accuracy: 0.7771\n",
      "Epoch 6/10\n",
      "631/631 [==============================] - 808s 1s/step - loss: 0.0840 - categorical_accuracy: 0.9691 - val_loss: 0.8948 - val_categorical_accuracy: 0.7742\n",
      "Epoch 7/10\n",
      "631/631 [==============================] - 916s 1s/step - loss: 0.0693 - categorical_accuracy: 0.9750 - val_loss: 1.0739 - val_categorical_accuracy: 0.7840\n",
      "Epoch 8/10\n",
      "631/631 [==============================] - 758s 1s/step - loss: 0.0664 - categorical_accuracy: 0.9757 - val_loss: 0.9935 - val_categorical_accuracy: 0.7889\n",
      "Epoch 9/10\n",
      "631/631 [==============================] - 755s 1s/step - loss: 0.0658 - categorical_accuracy: 0.9776 - val_loss: 1.1077 - val_categorical_accuracy: 0.7679\n",
      "Epoch 10/10\n",
      "631/631 [==============================] - 756s 1s/step - loss: 0.0452 - categorical_accuracy: 0.9841 - val_loss: 1.1116 - val_categorical_accuracy: 0.7882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f461726da10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train_body,X_train_head],[y_train], validation_data=([X_val_body,X_val_head],[y_val]), epochs=10 , batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb8569bc-dc67-4c5b-b69c-2b1b59859ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: glove300-embeddings/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: glove300-embeddings/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f461747e0d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f461747ecd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f43c5115050> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f45cc58ce10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"glove300-embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49e95e5d-80f3-4d0a-9938-4267c3d4d78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 25413\n",
      "Total bodies: 904\n"
     ]
    }
   ],
   "source": [
    "cd = DataSet(\"competition_test\")\n",
    "\n",
    "test_stances = cd.stances\n",
    "test_headlines = [stance['Headline'] for stance in test_stances]\n",
    "test_labels = [stance['Stance'] for stance in test_stances]\n",
    "test_body = [cd.articles[stance['Body ID']] for stance in test_stances]\n",
    "\n",
    "X_test_body = np.zeros((len(cd.stances), MAX_SENT_PER_ART, MAX_SENT_LEN), dtype='int32')\n",
    "sent_tok_test = []\n",
    "for article in test_body:\n",
    "    sent_tok_test.append(tokenize.sent_tokenize(article))\n",
    "\n",
    "for i, article in enumerate(sent_tok_test):\n",
    "    for j, sentence in enumerate(article[:MAX_SENT_PER_ART]):\n",
    "        words = text_to_word_sequence(sentence)\n",
    "        for k, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "            X_test_body[i][j][k] = word_index.get(word, 1)\n",
    "\n",
    "X_test_head = np.zeros((len(test_stances), MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, headline in enumerate(test_headlines):\n",
    "    words = text_to_word_sequence(headline)\n",
    "    for j, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "        X_test_head[i][j] = word_index.get(word, 1)\n",
    "\n",
    "\n",
    "predictions = model.predict([X_test_body,X_test_head])\n",
    "\n",
    "predicted_label = [LABELS[max([0, 1, 2, 3], key=lambda x: p[x])] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d608ba8b-9517-4e5b-bfa3-3b44538b008c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6456931491756188"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = sum([pl == a for pl, a in zip(predicted_label, test_labels)])/len(test_labels)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd68e27-221a-4f07-8cec-2b1687258ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
