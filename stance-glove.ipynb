{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64154fc6-e3b7-49c7-8d1f-e4f780c8a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1253dd1b-660d-4dc6-a83d-2c28fbd0aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.dataset import DataSet\n",
    "from utils.generate_test_splits import generate_hold_out_split, read_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c129e9-81ce-41c7-9b39-f32ddbd45702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 49972\n",
      "Total bodies: 1683\n"
     ]
    }
   ],
   "source": [
    "d = DataSet()\n",
    "generate_hold_out_split(d)\n",
    "trainID = set(read_ids(\"training_ids.txt\", \"splits\"))\n",
    "valID = set(read_ids(\"hold_out_ids.txt\", \"splits\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d497e-a281-483e-919d-f7de19848b76",
   "metadata": {},
   "source": [
    "# Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddbb7929-7d1b-4d19-bb39-44616297ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_PER_ART = 5\n",
    "MAX_SENT_LEN = 20\n",
    "MAX_VOCAB = 50000\n",
    "VECTOR_SIZE = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde4bb2d-2708-47a7-973a-01e5fcc8a90d",
   "metadata": {},
   "source": [
    "# Set up training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b760b24-8e38-448d-907d-7af8f556427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stances = [stance for stance in d.stances if stance['Body ID'] in trainID]\n",
    "train_headlines = [stance['Headline'] for stance in train_stances]\n",
    "train_labels = [stance['Stance'] for stance in train_stances]\n",
    "train_body = [d.articles[stance['Body ID']] for stance in train_stances]\n",
    "\n",
    "val_stances = [stance for stance in d.stances if stance['Body ID'] in valID]\n",
    "val_headlines = [stance['Headline'] for stance in val_stances]\n",
    "val_labels = [stance['Stance'] for stance in val_stances]\n",
    "val_body = [d.articles[stance['Body ID']] for stance in val_stances]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65809091-a13b-4e7d-8a32-868df58d08fe",
   "metadata": {},
   "source": [
    "# Vectorization and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "181b27ca-c449-43e4-9590-f9adace47b60",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sw26wong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import tokenize\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "nltk.download('punkt')\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=MAX_VOCAB, output_sequence_length=MAX_SENT_LEN)\n",
    "vectorizer.adapt(train_body + train_headlines + val_body + val_headlines)\n",
    "\n",
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "642b1bba-9a57-4a8f-a10a-f6ac30213805",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tok_art = []\n",
    "for article in train_body:\n",
    "    sent_tok_art.append(tokenize.sent_tokenize(article))\n",
    "\n",
    "vsent_tok_art = []\n",
    "for article in val_body:\n",
    "    vsent_tok_art.append(tokenize.sent_tokenize(article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cdf08ca-4e0d-44e9-a7d2-a03ef9c51cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_body = np.zeros((len(train_stances), MAX_SENT_PER_ART, MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, article in enumerate(sent_tok_art):\n",
    "    for j, sentence in enumerate(article[:MAX_SENT_PER_ART]):\n",
    "        words = text_to_word_sequence(sentence)\n",
    "        for k, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "            X_train_body[i][j][k] = word_index.get(word, 1) # get else UNK\n",
    "\n",
    "X_train_head = np.zeros((len(train_stances), MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, headline in enumerate(train_headlines):\n",
    "    words = text_to_word_sequence(headline)\n",
    "    for j, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "        X_train_head[i][j] = word_index.get(word, 1)\n",
    "\n",
    "X_val_body = np.zeros((len(val_stances), MAX_SENT_PER_ART, MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, article in enumerate(vsent_tok_art):\n",
    "    for j, sentence in enumerate(article[:MAX_SENT_PER_ART]):\n",
    "        words = text_to_word_sequence(sentence)\n",
    "        for k, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "            X_val_body[i][j][k] = word_index.get(word, 1)\n",
    "\n",
    "X_val_head = np.zeros((len(val_stances), MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, headline in enumerate(val_headlines):\n",
    "    words = text_to_word_sequence(headline)\n",
    "    for j, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "        X_val_head[i][j] = word_index.get(word, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfd06aba-72ed-49c9-98b0-7bac194968ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.Series(train_labels)\n",
    "one_hot = pd.get_dummies(targets,sparse = True)\n",
    "one_hot_labels = np.asarray(one_hot)\n",
    "y_train = one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68403e35-626a-42d6-aa04-526e60dabd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.Series(val_labels)\n",
    "one_hot = pd.get_dummies(targets,sparse = True)\n",
    "one_hot_labels = np.asarray(one_hot)\n",
    "y_val = one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a72497-cdc8-4976-b67a-3fb3ef770c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['agree', 'disagree', 'discuss', 'unrelated']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a94ed6b-68b8-4b6e-8474-7fffd9e9a84a",
   "metadata": {},
   "source": [
    "# Create Embedding Matrix from Google word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3323e80-750a-4051-be75-c556b5707f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_index)\n",
    "embedding_matrix = np.zeros((vocab_size+1, VECTOR_SIZE))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        v = wv[word]\n",
    "        embedding_matrix[i] = v\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d0a0552-dbda-49d8-bd95-730048919fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del wv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2260b21a-ab1e-4839-895d-220f5f01943d",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1b4925d-7332-4af8-b50e-9e91114af8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM, TimeDistributed, Activation\n",
    "from keras.layers import Flatten, Permute, merge, Input\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,multiply,concatenate,Dropout\n",
    "from keras.layers import GRU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5663cebf-696c-4dda-9d00-eb49b47fd728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "316/316 [==============================] - 210s 644ms/step - loss: 0.5860 - categorical_accuracy: 0.7871 - val_loss: 0.6747 - val_categorical_accuracy: 0.7146\n",
      "Epoch 2/25\n",
      "316/316 [==============================] - 207s 657ms/step - loss: 0.2630 - categorical_accuracy: 0.8961 - val_loss: 0.5735 - val_categorical_accuracy: 0.7775\n",
      "Epoch 3/25\n",
      "316/316 [==============================] - 162s 512ms/step - loss: 0.1527 - categorical_accuracy: 0.9405 - val_loss: 0.7002 - val_categorical_accuracy: 0.7905\n",
      "Epoch 4/25\n",
      "316/316 [==============================] - 149s 472ms/step - loss: 0.1032 - categorical_accuracy: 0.9611 - val_loss: 0.7918 - val_categorical_accuracy: 0.7716\n",
      "Epoch 5/25\n",
      "316/316 [==============================] - 155s 490ms/step - loss: 0.0760 - categorical_accuracy: 0.9726 - val_loss: 0.8814 - val_categorical_accuracy: 0.7910\n",
      "Epoch 6/25\n",
      "316/316 [==============================] - 153s 485ms/step - loss: 0.0587 - categorical_accuracy: 0.9785 - val_loss: 0.8437 - val_categorical_accuracy: 0.8064\n",
      "Epoch 7/25\n",
      "316/316 [==============================] - 170s 538ms/step - loss: 0.0472 - categorical_accuracy: 0.9833 - val_loss: 0.8535 - val_categorical_accuracy: 0.8173\n",
      "Epoch 8/25\n",
      "316/316 [==============================] - 137s 432ms/step - loss: 0.0442 - categorical_accuracy: 0.9847 - val_loss: 0.9956 - val_categorical_accuracy: 0.8027\n",
      "Epoch 9/25\n",
      "316/316 [==============================] - 138s 436ms/step - loss: 0.0449 - categorical_accuracy: 0.9846 - val_loss: 0.9079 - val_categorical_accuracy: 0.8189\n",
      "Epoch 10/25\n",
      "316/316 [==============================] - 138s 436ms/step - loss: 0.0315 - categorical_accuracy: 0.9891 - val_loss: 0.9655 - val_categorical_accuracy: 0.8091\n",
      "Epoch 11/25\n",
      "316/316 [==============================] - 138s 436ms/step - loss: 0.0344 - categorical_accuracy: 0.9885 - val_loss: 1.0302 - val_categorical_accuracy: 0.8192\n",
      "Epoch 12/25\n",
      "316/316 [==============================] - 138s 436ms/step - loss: 0.0249 - categorical_accuracy: 0.9919 - val_loss: 1.1634 - val_categorical_accuracy: 0.8143\n",
      "Epoch 13/25\n",
      "316/316 [==============================] - 138s 436ms/step - loss: 0.0340 - categorical_accuracy: 0.9891 - val_loss: 0.9757 - val_categorical_accuracy: 0.8257\n",
      "Epoch 14/25\n",
      "316/316 [==============================] - 137s 434ms/step - loss: 0.0334 - categorical_accuracy: 0.9894 - val_loss: 1.0775 - val_categorical_accuracy: 0.8285\n",
      "Epoch 15/25\n",
      "316/316 [==============================] - 138s 436ms/step - loss: 0.0191 - categorical_accuracy: 0.9937 - val_loss: 1.3443 - val_categorical_accuracy: 0.8139\n",
      "Epoch 16/25\n",
      "316/316 [==============================] - 139s 438ms/step - loss: 0.0258 - categorical_accuracy: 0.9923 - val_loss: 1.1984 - val_categorical_accuracy: 0.8162\n",
      "Epoch 17/25\n",
      "316/316 [==============================] - 138s 437ms/step - loss: 0.0187 - categorical_accuracy: 0.9938 - val_loss: 1.3247 - val_categorical_accuracy: 0.8168\n",
      "Epoch 18/25\n",
      "316/316 [==============================] - 139s 439ms/step - loss: 0.0331 - categorical_accuracy: 0.9897 - val_loss: 1.5054 - val_categorical_accuracy: 0.8074\n",
      "Epoch 19/25\n",
      "316/316 [==============================] - 138s 438ms/step - loss: 0.0261 - categorical_accuracy: 0.9919 - val_loss: 1.2739 - val_categorical_accuracy: 0.8156\n",
      "Epoch 20/25\n",
      "316/316 [==============================] - 138s 438ms/step - loss: 0.0225 - categorical_accuracy: 0.9934 - val_loss: 1.2745 - val_categorical_accuracy: 0.8259\n",
      "Epoch 21/25\n",
      "316/316 [==============================] - 138s 436ms/step - loss: 0.0148 - categorical_accuracy: 0.9955 - val_loss: 1.2591 - val_categorical_accuracy: 0.8150\n",
      "Epoch 22/25\n",
      "316/316 [==============================] - 138s 436ms/step - loss: 0.0117 - categorical_accuracy: 0.9963 - val_loss: 1.5078 - val_categorical_accuracy: 0.8118\n",
      "Epoch 23/25\n",
      "316/316 [==============================] - 138s 436ms/step - loss: 0.0131 - categorical_accuracy: 0.9962 - val_loss: 1.4338 - val_categorical_accuracy: 0.8201\n",
      "Epoch 24/25\n",
      "316/316 [==============================] - 139s 438ms/step - loss: 0.0230 - categorical_accuracy: 0.9929 - val_loss: 1.5483 - val_categorical_accuracy: 0.8075\n",
      "Epoch 25/25\n",
      "316/316 [==============================] - 139s 439ms/step - loss: 0.0263 - categorical_accuracy: 0.9924 - val_loss: 1.6113 - val_categorical_accuracy: 0.8057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6ba393fed0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = VECTOR_SIZE\n",
    "\n",
    "sentence_input = Input(shape=(MAX_SENT_LEN,),dtype='int32')\n",
    "embedded_sequences = Embedding(output_dim=hidden_size, \n",
    "                               input_dim=vocab_size+1, \n",
    "                               input_length=MAX_SENT_LEN,\n",
    "                               weights=[embedding_matrix],\n",
    "                               trainable=True,\n",
    "                               mask_zero=False,)(sentence_input)\n",
    "l_LSTM = Bidirectional(LSTM(hidden_size, return_sequences=True))(embedded_sequences)\n",
    "l_dense = TimeDistributed(Dense(hidden_size))(l_LSTM)\n",
    "l_dense = Flatten()(l_dense)\n",
    "sentEncoder = Model(sentence_input,l_dense)\n",
    "\n",
    "body_input = Input(shape=(MAX_SENT_PER_ART,MAX_SENT_LEN,),dtype = 'int32')\n",
    "body_encoder = TimeDistributed(sentEncoder)(body_input)\n",
    "\n",
    "l_LSTM_sent = Bidirectional(LSTM(hidden_size,return_sequences=True))(body_encoder)\n",
    "l_dense_sent = TimeDistributed(Dense(hidden_size))(l_LSTM_sent)\n",
    "l_dense_sent = Flatten()(l_dense_sent)\n",
    "\n",
    "heading_input = Input(shape=(MAX_SENT_LEN,) ,dtype = 'int32')\n",
    "heading_embedded_sequences = Embedding(output_dim=hidden_size, input_dim=vocab_size+1, \\\n",
    "                                       input_length=(MAX_SENT_LEN,), \\\n",
    "                                      weights=[embedding_matrix],\n",
    "                                      trainable=True,\n",
    "                                      mask_zero=False,)(heading_input)\n",
    "h_dense = Dense(hidden_size,activation='relu')(heading_embedded_sequences)\n",
    "h_flatten = Flatten()(h_dense)\n",
    "\n",
    "article_output = concatenate([l_dense_sent,h_flatten],name = 'concatenate_heading')\n",
    "\n",
    "news_vestor = Dense(hidden_size,activation = 'relu')(article_output)\n",
    "preds = Dense(4 ,activation='softmax')(news_vestor)\n",
    "model = Model([body_input,heading_input],[preds])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model.fit([X_train_body,X_train_head],[y_train], validation_data=([X_val_body,X_val_head],[y_val]), epochs=25 , batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49e95e5d-80f3-4d0a-9938-4267c3d4d78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 25413\n",
      "Total bodies: 904\n"
     ]
    }
   ],
   "source": [
    "cd = DataSet(\"competition_test\")\n",
    "\n",
    "\n",
    "test_stances = cd.stances\n",
    "test_headlines = [stance['Headline'] for stance in test_stances]\n",
    "test_labels = [stance['Stance'] for stance in test_stances]\n",
    "test_body = [cd.articles[stance['Body ID']] for stance in test_stances]\n",
    "\n",
    "X_test_body = np.zeros((len(cd.stances), MAX_SENT_PER_ART, MAX_SENT_LEN), dtype='int32')\n",
    "sent_tok_test = []\n",
    "for article in test_body:\n",
    "    sent_tok_test.append(tokenize.sent_tokenize(article))\n",
    "\n",
    "for i, article in enumerate(sent_tok_test):\n",
    "    for j, sentence in enumerate(article[:MAX_SENT_PER_ART]):\n",
    "        words = text_to_word_sequence(sentence)\n",
    "        for k, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "            X_test_body[i][j][k] = word_index.get(word, 1)\n",
    "\n",
    "X_test_head = np.zeros((len(test_stances), MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, headline in enumerate(test_headlines):\n",
    "    words = text_to_word_sequence(headline)\n",
    "    for j, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "        X_test_head[i][j] = word_index.get(word, 1)\n",
    "\n",
    "\n",
    "predictions = model.predict([X_test_body,X_test_head])\n",
    "\n",
    "predicted_label = [LABELS[max([0, 1, 2, 3], key=lambda x: p[x])] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d608ba8b-9517-4e5b-bfa3-3b44538b008c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6924802266556487"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = sum([pl == a for pl, a in zip(predicted_label, test_labels)])/len(test_labels)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a637e749-89d4-4a25-a91e-0a6473b573e9",
   "metadata": {},
   "source": [
    "# Glove 100\n",
    "- 66% with masked zeros, not trainable\n",
    "\n",
    "- 68% with no mask zero, not trainable\n",
    "\n",
    "- 69% no mask zero, trainable\n",
    "\n",
    "- 65% no mask zero, trainable + double-relu\n",
    "\n",
    "- 66% no mask zero, trainable + single-relu\n",
    "\n",
    "- 67.5% no mask zero, not trainable, 2048 batch\n",
    "- 72.5% no mask zero, not trainable, 1024 batch\n",
    "- 72.3% no mask zero, not trainable, 512 batch\n",
    "- 72.0% no mask zero, not trainable 256 batch\n",
    "- 72.8% no mask zero, not trainable, 128 batch\n",
    "\n",
    "- 73.2% no mask zero, not trainable, 128 batch 25 epoch\n",
    "\n",
    "- 71.9% no mask zero, not trainable, 1024 batch 30 epochs\n",
    "- 72.2% no mask zero, not trainable, 1024 batch 15 epochs\n",
    "- 73.22% no mask zero, not trainable, 1024 batch 20 epochs\n",
    "- 72.9% no mask zero, not trainable, 1024 batch 25 epochs\n",
    "- 72.7% no mask zero, not trainable, 1024 batch 30 epochs\n",
    "\n",
    "# Glove 200\n",
    "- 68% no mask zero, trainable + single-relu\n",
    "\n",
    "# Glove 300\n",
    "- 69% trainable 25 epoch\n",
    "- 72% no mask zero, trainable\n",
    "- 72.3% no mask zero, not trainable\n",
    "- 73.8% no mask zero, not trainable, 128 batch 25 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3728af44-ce49-4777-b290-1ba997735a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: glove300-embeddings-trainable/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: glove300-embeddings-trainable/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f6ba389fed0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f6ba38a3a90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f6bd04ef510> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f6bcbd21ad0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"glove300-embeddings-trainable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f187f6-18af-444a-841f-394be5b5eb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
