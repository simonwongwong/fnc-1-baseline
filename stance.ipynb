{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64154fc6-e3b7-49c7-8d1f-e4f780c8a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1253dd1b-660d-4dc6-a83d-2c28fbd0aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.dataset import DataSet\n",
    "from utils.generate_test_splits import generate_hold_out_split, read_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c129e9-81ce-41c7-9b39-f32ddbd45702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 49972\n",
      "Total bodies: 1683\n"
     ]
    }
   ],
   "source": [
    "d = DataSet()\n",
    "generate_hold_out_split(d, training=0.8)\n",
    "trainID = set(read_ids(\"training_ids.txt\", \"splits\"))\n",
    "valID = set(read_ids(\"hold_out_ids.txt\", \"splits\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d497e-a281-483e-919d-f7de19848b76",
   "metadata": {},
   "source": [
    "# Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddbb7929-7d1b-4d19-bb39-44616297ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_PER_ART = 5\n",
    "MAX_SENT_LEN = 20\n",
    "MAX_VOCAB = 50000\n",
    "VECTOR_SIZE = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde4bb2d-2708-47a7-973a-01e5fcc8a90d",
   "metadata": {},
   "source": [
    "# Set up training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b760b24-8e38-448d-907d-7af8f556427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stances = [stance for stance in d.stances if stance['Body ID'] in trainID]\n",
    "train_headlines = [stance['Headline'] for stance in train_stances]\n",
    "train_labels = [stance['Stance'] for stance in train_stances]\n",
    "train_body = [d.articles[stance['Body ID']] for stance in train_stances]\n",
    "\n",
    "val_stances = [stance for stance in d.stances if stance['Body ID'] in valID]\n",
    "val_headlines = [stance['Headline'] for stance in val_stances]\n",
    "val_labels = [stance['Stance'] for stance in val_stances]\n",
    "val_body = [d.articles[stance['Body ID']] for stance in val_stances]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65809091-a13b-4e7d-8a32-868df58d08fe",
   "metadata": {},
   "source": [
    "# Vectorization and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78f7498-12c2-40fb-a2bb-81a0bcbca829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sw26wong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import tokenize\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "nltk.download('punkt')\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=MAX_VOCAB, output_sequence_length=MAX_SENT_LEN)\n",
    "vectorizer.adapt(train_body + train_headlines + val_body + val_headlines)\n",
    "\n",
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "642b1bba-9a57-4a8f-a10a-f6ac30213805",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tok_art = []\n",
    "for article in train_body:\n",
    "    sent_tok_art.append(tokenize.sent_tokenize(article))\n",
    "\n",
    "vsent_tok_art = []\n",
    "for article in val_body:\n",
    "    vsent_tok_art.append(tokenize.sent_tokenize(article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f98757-8f2e-426d-8876-ffae9b238771",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_body = np.zeros((len(train_stances), MAX_SENT_PER_ART, MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, article in enumerate(sent_tok_art):\n",
    "    for j, sentence in enumerate(article[:MAX_SENT_PER_ART]):\n",
    "        words = text_to_word_sequence(sentence)\n",
    "        for k, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "            X_train_body[i][j][k] = word_index.get(word, 1) # get else UNK\n",
    "\n",
    "X_train_head = np.zeros((len(train_stances), MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, headline in enumerate(train_headlines):\n",
    "    words = text_to_word_sequence(headline)\n",
    "    for j, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "        X_train_head[i][j] = word_index.get(word, 1)\n",
    "\n",
    "X_val_body = np.zeros((len(val_stances), MAX_SENT_PER_ART, MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, article in enumerate(vsent_tok_art):\n",
    "    for j, sentence in enumerate(article[:MAX_SENT_PER_ART]):\n",
    "        words = text_to_word_sequence(sentence)\n",
    "        for k, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "            X_val_body[i][j][k] = word_index.get(word, 1)\n",
    "\n",
    "X_val_head = np.zeros((len(val_stances), MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, headline in enumerate(val_headlines):\n",
    "    words = text_to_word_sequence(headline)\n",
    "    for j, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "        X_val_head[i][j] = word_index.get(word, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfd06aba-72ed-49c9-98b0-7bac194968ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.Series(train_labels)\n",
    "one_hot = pd.get_dummies(targets,sparse = True)\n",
    "one_hot_labels = np.asarray(one_hot)\n",
    "y_train = one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68403e35-626a-42d6-aa04-526e60dabd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.Series(val_labels)\n",
    "one_hot = pd.get_dummies(targets,sparse = True)\n",
    "one_hot_labels = np.asarray(one_hot)\n",
    "y_val = one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a72497-cdc8-4976-b67a-3fb3ef770c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['agree', 'disagree', 'discuss', 'unrelated']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a94ed6b-68b8-4b6e-8474-7fffd9e9a84a",
   "metadata": {},
   "source": [
    "# Create Embedding Matrix from Google word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3323e80-750a-4051-be75-c556b5707f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_index)\n",
    "embedding_matrix = np.zeros((vocab_size+1, VECTOR_SIZE))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        v = wv[word]\n",
    "        embedding_matrix[i] = v\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fc46b7-cf7c-4c9d-b707-8f4d66a194a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del wv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2260b21a-ab1e-4839-895d-220f5f01943d",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1b4925d-7332-4af8-b50e-9e91114af8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM, TimeDistributed, Activation\n",
    "from keras.layers import Flatten, Permute, merge, Input\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,multiply,concatenate,Dropout\n",
    "from keras.layers import GRU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c6624ea-0440-4024-b8fd-12392d3683f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = VECTOR_SIZE\n",
    "\n",
    "sentence_input = Input(shape=(MAX_SENT_LEN,),dtype='int32')\n",
    "\n",
    "embedded_sequences = Embedding(output_dim=hidden_size, \n",
    "                               input_dim=vocab_size+1, \n",
    "                               input_length=MAX_SENT_LEN,\n",
    "                               weights=[embedding_matrix],\n",
    "                               trainable=False,\n",
    "                               mask_zero=True,\n",
    "                    )(sentence_input)\n",
    "\n",
    "l_LSTM = Bidirectional(LSTM(hidden_size,return_sequences = True))(embedded_sequences)\n",
    "l_dense = TimeDistributed(Dense(hidden_size))(l_LSTM)\n",
    "l_dense = Flatten()(l_dense)\n",
    "sentEncoder = Model(sentence_input,l_dense)\n",
    "\n",
    "body_input = Input(shape=(MAX_SENT_PER_ART,MAX_SENT_LEN,),dtype = 'int32')\n",
    "\n",
    "body_encoder = TimeDistributed(sentEncoder)(body_input)\n",
    "\n",
    "l_LSTM_sent = Bidirectional(LSTM(hidden_size,return_sequences=True))(body_encoder)\n",
    "l_dense_sent = TimeDistributed(Dense(hidden_size))(l_LSTM_sent)\n",
    "l_dense_sent = Flatten()(l_dense_sent)\n",
    "\n",
    "heading_input = Input(shape = (MAX_SENT_LEN, ),dtype = 'int32')\n",
    "heading_embedded_sequences = Embedding(output_dim=hidden_size, input_dim=vocab_size+1, \\\n",
    "                                       input_length = (MAX_SENT_LEN,), \\\n",
    "                                      weights = [embedding_matrix],\n",
    "                                      trainable=False,\n",
    "                                      mask_zero=True,)(heading_input)\n",
    "h_dense = Dense(hidden_size,activation='relu')(heading_embedded_sequences)\n",
    "h_flatten = Flatten()(h_dense)\n",
    "article_output = concatenate([l_dense_sent,h_flatten],name = 'concatenate_heading')\n",
    "\n",
    "news_vestor = Dense(hidden_size,activation = 'relu')(article_output)\n",
    "preds = Dense(4,activation = 'softmax')(news_vestor)\n",
    "model = Model([body_input,heading_input],[preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "961c4571-36a5-492c-af9b-3880370db565",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0b21d5f-2a72-4e29-bed1-02e6b8d2c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "316/316 [==============================] - 160s 475ms/step - loss: 0.5646 - categorical_accuracy: 0.7913 - val_loss: 0.7205 - val_categorical_accuracy: 0.7101\n",
      "Epoch 2/15\n",
      "316/316 [==============================] - 147s 465ms/step - loss: 0.2900 - categorical_accuracy: 0.8865 - val_loss: 0.7330 - val_categorical_accuracy: 0.7253\n",
      "Epoch 3/15\n",
      "316/316 [==============================] - 146s 463ms/step - loss: 0.1728 - categorical_accuracy: 0.9321 - val_loss: 0.6709 - val_categorical_accuracy: 0.7690\n",
      "Epoch 4/15\n",
      "316/316 [==============================] - 146s 463ms/step - loss: 0.1131 - categorical_accuracy: 0.9567 - val_loss: 0.7652 - val_categorical_accuracy: 0.7717\n",
      "Epoch 5/15\n",
      "316/316 [==============================] - 146s 462ms/step - loss: 0.0805 - categorical_accuracy: 0.9690 - val_loss: 0.7778 - val_categorical_accuracy: 0.7751\n",
      "Epoch 6/15\n",
      "316/316 [==============================] - 146s 461ms/step - loss: 0.0662 - categorical_accuracy: 0.9755 - val_loss: 0.8247 - val_categorical_accuracy: 0.7849\n",
      "Epoch 7/15\n",
      "316/316 [==============================] - 145s 460ms/step - loss: 0.0493 - categorical_accuracy: 0.9820 - val_loss: 1.0570 - val_categorical_accuracy: 0.7812\n",
      "Epoch 8/15\n",
      "316/316 [==============================] - 146s 461ms/step - loss: 0.0477 - categorical_accuracy: 0.9838 - val_loss: 0.9013 - val_categorical_accuracy: 0.7942\n",
      "Epoch 9/15\n",
      "316/316 [==============================] - 146s 461ms/step - loss: 0.0345 - categorical_accuracy: 0.9882 - val_loss: 1.1193 - val_categorical_accuracy: 0.7866\n",
      "Epoch 10/15\n",
      "316/316 [==============================] - 145s 458ms/step - loss: 0.0333 - categorical_accuracy: 0.9892 - val_loss: 1.0458 - val_categorical_accuracy: 0.8014\n",
      "Epoch 11/15\n",
      "316/316 [==============================] - 145s 458ms/step - loss: 0.0346 - categorical_accuracy: 0.9880 - val_loss: 1.1978 - val_categorical_accuracy: 0.7746\n",
      "Epoch 12/15\n",
      "316/316 [==============================] - 145s 460ms/step - loss: 0.0326 - categorical_accuracy: 0.9892 - val_loss: 1.3803 - val_categorical_accuracy: 0.7698\n",
      "Epoch 13/15\n",
      "316/316 [==============================] - 145s 458ms/step - loss: 0.0318 - categorical_accuracy: 0.9897 - val_loss: 1.1808 - val_categorical_accuracy: 0.7731\n",
      "Epoch 14/15\n",
      "316/316 [==============================] - 144s 456ms/step - loss: 0.0258 - categorical_accuracy: 0.9920 - val_loss: 1.1496 - val_categorical_accuracy: 0.7925\n",
      "Epoch 15/15\n",
      "316/316 [==============================] - 144s 456ms/step - loss: 0.0138 - categorical_accuracy: 0.9963 - val_loss: 1.0382 - val_categorical_accuracy: 0.8115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb516208d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train_body,X_train_head],[y_train], validation_data=([X_val_body,X_val_head],[y_val]), epochs=15 , batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "218e762b-b9f1-4c6f-8821-eff73745b271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 25413\n",
      "Total bodies: 904\n"
     ]
    }
   ],
   "source": [
    "cd = DataSet(\"competition_test\")\n",
    "\n",
    "test_stances = cd.stances\n",
    "test_headlines = [stance['Headline'] for stance in test_stances]\n",
    "test_labels = [stance['Stance'] for stance in test_stances]\n",
    "test_body = [cd.articles[stance['Body ID']] for stance in test_stances]\n",
    "\n",
    "X_test_body = np.zeros((len(test_stances), MAX_SENT_PER_ART, MAX_SENT_LEN), dtype='int32')\n",
    "sent_tok_test = []\n",
    "for article in test_body:\n",
    "    sent_tok_test.append(tokenize.sent_tokenize(article))\n",
    "\n",
    "for i, article in enumerate(sent_tok_test):\n",
    "    for j, sentence in enumerate(article[:MAX_SENT_PER_ART]):\n",
    "        words = text_to_word_sequence(sentence)\n",
    "        for k, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "            X_test_body[i][j][k] = word_index.get(word, 1)\n",
    "\n",
    "X_test_head = np.zeros((len(test_stances), MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, headline in enumerate(test_headlines):\n",
    "    words = text_to_word_sequence(headline)\n",
    "    for j, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "        X_test_head[i][j] = word_index.get(word, 1)\n",
    "\n",
    "\n",
    "predictions = model.predict([X_test_body,X_test_head])\n",
    "predicted_label = [LABELS[max([0, 1, 2, 3], key=lambda x: p[x])] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d608ba8b-9517-4e5b-bfa3-3b44538b008c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7313186164561445"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = sum([pl == a for pl, a in zip(predicted_label, test_labels)])/len(test_labels)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4f7f78c-364c-4e21-ba85-2b03d2fc9959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: google300-embeddings-nontrainable/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: google300-embeddings-nontrainable/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7efea9e70090> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7efea9e70bd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7efb516cef10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7efb51631750> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"google300-embeddings-nontrainable\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
