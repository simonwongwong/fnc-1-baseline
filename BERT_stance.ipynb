{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aggs.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependency"
      ],
      "metadata": {
        "id": "p4IwB18mBOI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install simpletransformers "
      ],
      "metadata": {
        "id": "WOAhvY9eBSyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import ClassificationModel\n",
        "\n",
        "- simpletransformers provides abstractions for `torch` and `transformers` (Hugging Face) implementations "
      ],
      "metadata": {
        "id": "RAlX9PQ5BWEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from simpletransformers.classification import (\n",
        "    ClassificationModel, ClassificationArgs\n",
        ")"
      ],
      "metadata": {
        "id": "Mv0yHUdlYnuk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define function to load and (optional) split fnc data into training and val"
      ],
      "metadata": {
        "id": "h2lmGpyp8BVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "FNC1_DATA_PATH = '/content/drive/MyDrive/fnc-1'\n",
        "\n",
        "STANCE_2_ID = {'agree': 0, 'disagree': 1, 'discuss': 2, 'unrelated': 3}\n",
        "\n",
        "SENTENCE_PAIR_COLS = ['text_a', 'text_b', 'labels']\n",
        "def combine_headline_body_and_split_train_val(body_path, headline_path, split=True, body_dict={}):\n",
        "    body_csv_df = pd.read_csv(body_path)\n",
        "    df = body_csv_df.reset_index()\n",
        "    for index, row in body_csv_df.iterrows():\n",
        "        body_dict[row[\"Body ID\"]] = row[\"articleBody\"]\n",
        "\n",
        "    headlines, bodies, labels = [], [], []\n",
        "    headline_csv_df = pd.read_csv(headline_path)\n",
        "    df = headline_csv_df.reset_index()\n",
        "    for index, row in headline_csv_df.iterrows():\n",
        "        headlines.append(row[\"Headline\"])\n",
        "        bodies.append(body_dict[row[\"Body ID\"]])\n",
        "        labels.append(STANCE_2_ID[row[\"Stance\"]])\n",
        "\n",
        "    combined_df = pd.DataFrame(list(zip(headlines, bodies, labels)), columns=SENTENCE_PAIR_COLS)\n",
        "    if not split:\n",
        "      labels_df = pd.Series(combined_df['labels']).to_numpy()\n",
        "      return combined_df, labels_df\n",
        "\n",
        "    train_df, val_df = train_test_split(combined_df)\n",
        "    return train_df, val_df, pd.Series(val_df['labels']).to_numpy()\n"
      ],
      "metadata": {
        "id": "r4PWrxOxattA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Evaluate Model Function to calculate F1 scores and accurary"
      ],
      "metadata": {
        "id": "kpTEeDWtRlgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "LABELS = [0, 1, 2, 3]\n",
        "RELATED = [0, 1, 2]\n",
        "CONFUSION_MATRIX = [[0, 0, 0, 0],\n",
        "          [0, 0, 0, 0],\n",
        "          [0, 0, 0, 0],\n",
        "          [0, 0, 0, 0]]\n",
        "\n",
        "\n",
        "def calc_f1(real_labels, predicted_labels):\n",
        "    f1_macro = f1_score(real_labels, predicted_labels, average='macro')\n",
        "    f1_classwise = f1_score(real_labels, predicted_labels, average=None, labels=[0, 1, 2, 3])\n",
        "    return f1_macro, f1_classwise\n",
        "\n",
        "\n",
        "def calculate_accuracy(predicted_labels, real_labels):\n",
        "    score = 0.0\n",
        "    cm = CONFUSION_MATRIX\n",
        "    for i, (g, t) in enumerate(zip(predicted_labels, real_labels)):\n",
        "      cm[g][t] += 1\n",
        "    \n",
        "    hit, total = 0, 0\n",
        "    for i, row in enumerate(cm):\n",
        "        hit += row[i]\n",
        "        total += sum(row)\n",
        "    return (hit / total)*100\n",
        "\n",
        "def evaluate_model(model, test_df):\n",
        "    _, outputs, _ = model.eval_model(test_df)\n",
        "    predictions = np.argmax(outputs, axis=1)\n",
        "    print(calc_f1(predictions, test_labels))\n",
        "    print(calculate_accuracy(predictions, test_labels))"
      ],
      "metadata": {
        "id": "_kuBUwE6RMro"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Training and Val Data and Labels"
      ],
      "metadata": {
        "id": "c3_OZN6VJoqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df, labels_val = combine_headline_body_and_split_train_val(\n",
        "    os.path.join(FNC1_DATA_PATH, 'train_bodies.csv'),\n",
        "    os.path.join(FNC1_DATA_PATH, 'train_stances.csv'),\n",
        ")"
      ],
      "metadata": {
        "id": "lRLb0cHjJX4B"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Competition Test Data and Labels"
      ],
      "metadata": {
        "id": "bF4Z_Fx5KOj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df, test_labels = combine_headline_body_and_split_train_val(\n",
        "    os.path.join(FNC1_DATA_PATH, 'competition_test_bodies.csv'),\n",
        "    os.path.join(FNC1_DATA_PATH, 'competition_test_stances.csv'),\n",
        "    split=False\n",
        ")"
      ],
      "metadata": {
        "id": "Y719MbTLKLvQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Tune Model with BERT"
      ],
      "metadata": {
        "id": "nk-Yc2-TMvuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = ClassificationModel(\n",
        "    'bert', \n",
        "    'bert-base', \n",
        "    use_cuda=True,\n",
        "    num_labels=4, \n",
        "    args={\n",
        "      'fp16': True, \n",
        "       # Tune hyperparameter 3e-4, 1e-4, 5e-5, 3e-5\n",
        "      'learning_rate':3e-5,\n",
        "      'num_train_epochs': 4,\n",
        "      'reprocess_input_data': True,\n",
        "      'overwrite_output_dir': True,\n",
        "      'process_count': 10,\n",
        "      'train_batch_size': 8,\n",
        "      'eval_batch_size': 8,\n",
        "      'max_seq_length': 512\n",
        "    # 'output_dir': ''\n",
        "})\n",
        "\n",
        "# TRAIN\n",
        "bert_model.train_model(train_df)\n",
        "evaluate_model(bert_model, test_labels)\n",
        "\n",
        "# TUNE\n",
        "bert_model.train_model(val_df)\n",
        "evaluate_model(bert_model, labels_val)"
      ],
      "metadata": {
        "id": "QABtkgKHMxvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Tune Model with RoBERTa\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "MZke8LTn7zVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roberta_model = ClassificationModel(\n",
        "    'roberta', \n",
        "    'roberta-base', \n",
        "    use_cuda=True,\n",
        "    num_labels=4, \n",
        "    args={\n",
        "      'fp16': True, \n",
        "      # Tune hyperparameter 3e-4, 1e-4, 5e-5, 3e-5\n",
        "      'learning_rate':5e-5,\n",
        "      'num_train_epochs': 4,\n",
        "      'reprocess_input_data': True,\n",
        "      'overwrite_output_dir': True,\n",
        "      'process_count': 10,\n",
        "      'train_batch_size': 8,\n",
        "      'eval_batch_size': 8,\n",
        "      'max_seq_length': 512,\n",
        "    # 'output_dir': ''\n",
        "})\n",
        "\n",
        "# TRAIN\n",
        "roberta_model.train_model(train_df)\n",
        "evaluate_model(roberta_model, test_labels)\n",
        "\n",
        "# TUNE\n",
        "roberta_model.train_model(val_df)\n",
        "evaluate_model(roberta_model, labels_val)"
      ],
      "metadata": {
        "id": "cXt3i-2qa6t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Competition Submission Prediction\n"
      ],
      "metadata": {
        "id": "9z_EJJJU7lOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "FNC1_DATA_PATH = '/content/drive/MyDrive/fnc-1'\n",
        "\n",
        "body_dict = {}\n",
        "body_csv_df = pd.read_csv(os.path.join(FNC1_DATA_PATH, 'competition_test_bodies.csv'))\n",
        "df = body_csv_df.reset_index()\n",
        "for index, row in body_csv_df.iterrows():\n",
        "    body_dict[row[\"Body ID\"]] = row[\"articleBody\"]\n",
        "\n",
        "headlines, bodies, combined_headline_bodies = [], [], []\n",
        "headline_csv_df = pd.read_csv(os.path.join(FNC1_DATA_PATH, 'competition_test_stances_unlabeled.csv'))\n",
        "df = headline_csv_df.reset_index()\n",
        "for index, row in headline_csv_df.iterrows():\n",
        "    headlines.append(row[\"Headline\"])\n",
        "    bodies.append(row[\"Body ID\"])\n",
        "    combined_headline_bodies.append(row[\"Headline\"], body_dict[row[\"Body ID\"]])\n",
        "\n",
        "predictions, raw_outputs = roberta_model.predict(combined_headline_bodies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guBFb5SzbUKs",
        "outputId": "9fbc6997-0d61-43a2-cdd0-d5c25bd14fa1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Store and format submission csv"
      ],
      "metadata": {
        "id": "BJJ0G7RrXyHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(zip(headlines, bodies, predictions)), columns=['Headline', 'Body ID', 'Stance'])\n",
        "df['Stance'] = df['Stance'].replace({0: 'agree', 1: 'disagree', 2: 'discuss', 3: 'unrelated'})\n",
        "df.to_csv('answer.csv', index=False, encoding='utf-8') # From pandas library"
      ],
      "metadata": {
        "id": "8kl0curwpxNn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}