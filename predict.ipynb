{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b097fcd-3540-4f75-a10e-43b1e4a29a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from utils.dataset import DataSet\n",
    "import numpy as np\n",
    "MAX_SENT_PER_ART = 5\n",
    "MAX_SENT_LEN = 20\n",
    "MAX_VOCAB = 50000\n",
    "VECTOR_SIZE = 100\n",
    "LABELS = ['agree', 'disagree', 'discuss', 'unrelated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ac4bc87-9d4d-4d80-85b5-e7d8a32ed176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sw26wong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 49972\n",
      "Total bodies: 1683\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import tokenize\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from utils.generate_test_splits import generate_hold_out_split, read_ids\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "d = DataSet()\n",
    "generate_hold_out_split(d, training=0.9)\n",
    "trainID = set(read_ids(\"training_ids.txt\", \"splits\"))\n",
    "valID = set(read_ids(\"hold_out_ids.txt\", \"splits\"))\n",
    "\n",
    "train_stances = [stance for stance in d.stances if stance['Body ID'] in trainID]\n",
    "train_headlines = [stance['Headline'] for stance in train_stances]\n",
    "train_labels = [stance['Stance'] for stance in train_stances]\n",
    "train_body = [d.articles[stance['Body ID']] for stance in train_stances]\n",
    "\n",
    "val_stances = [stance for stance in d.stances if stance['Body ID'] in valID]\n",
    "val_headlines = [stance['Headline'] for stance in val_stances]\n",
    "val_labels = [stance['Stance'] for stance in val_stances]\n",
    "val_body = [d.articles[stance['Body ID']] for stance in val_stances]\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=MAX_VOCAB, output_sequence_length=MAX_SENT_LEN)\n",
    "vectorizer.adapt(train_body + train_headlines + val_body + val_headlines)\n",
    "\n",
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c860585-9208-4868-97ba-1234b193693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 25413\n",
      "Total bodies: 904\n"
     ]
    }
   ],
   "source": [
    "cd = DataSet(\"competition_test\")\n",
    "\n",
    "\n",
    "test_stances = cd.stances\n",
    "test_headlines = [stance['Headline'] for stance in test_stances]\n",
    "test_labels = [stance['Stance'] for stance in test_stances]\n",
    "test_body = [cd.articles[stance['Body ID']] for stance in test_stances]\n",
    "\n",
    "X_test_body = np.zeros((len(cd.stances), MAX_SENT_PER_ART, MAX_SENT_LEN), dtype='int32')\n",
    "sent_tok_test = []\n",
    "for article in test_body:\n",
    "    sent_tok_test.append(tokenize.sent_tokenize(article))\n",
    "\n",
    "for i, article in enumerate(sent_tok_test):\n",
    "    for j, sentence in enumerate(article[:MAX_SENT_PER_ART]):\n",
    "        words = text_to_word_sequence(sentence)\n",
    "        for k, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "            X_test_body[i][j][k] = word_index.get(word, 1)\n",
    "\n",
    "X_test_head = np.zeros((len(test_stances), MAX_SENT_LEN), dtype='int32')\n",
    "\n",
    "for i, headline in enumerate(test_headlines):\n",
    "    words = text_to_word_sequence(headline)\n",
    "    for j, word in enumerate(words[:MAX_SENT_LEN]):\n",
    "        X_test_head[i][j] = word_index.get(word, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a9c155-dc8c-43ba-bb0d-6ce6dd9d89a3",
   "metadata": {},
   "source": [
    "# Glove 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fdd83c9-c71b-4d3e-9c69-437345843cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"glove100-embeddings-trainable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d443817-3f6c-403c-8267-2bdb9de3605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([X_test_body,X_test_head])\n",
    "\n",
    "predicted_label = [LABELS[max([0, 1, 2, 3], key=lambda x: p[x])] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "582c5aa0-928f-463d-a5c0-422ddbfc61c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7398969031598001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = sum([pl == a for pl, a in zip(predicted_label, test_labels)])/len(test_labels)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce0a92cb-73cf-4fab-af51-78e6cb593c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unrelated', 79.44359186243261),\n",
       " ('discuss', 14.453232597489475),\n",
       " ('agree', 5.973320741352851),\n",
       " ('disagree', 0.12985479872506198)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v*100/len(predicted_label)) for k,v in Counter(predicted_label).most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1197b0a-fdb9-481e-a604-911f2b3e2a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unrelated', 73.13095333386697),\n",
       " ('discuss', 17.82798367085568),\n",
       " ('agree', 7.3601216681341555),\n",
       " ('disagree', 1.6809413271432)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v*100/len(train_labels + val_labels)) for k,v in  Counter(train_labels + val_labels).most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30bad146-c078-4ba5-835b-8499abd934b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unrelated', 72.20320308503521),\n",
       " ('discuss', 17.565812772990203),\n",
       " ('agree', 7.4882933931452405),\n",
       " ('disagree', 2.7426907488293395)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v*100/len(test_labels)) for k,v in Counter(test_labels).most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b762839-b0f3-4e78-a2d6-d8e8848544e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.29      0.23      0.26      1903\n",
      "    disagree       0.24      0.01      0.02       697\n",
      "     discuss       0.53      0.44      0.48      4464\n",
      "   unrelated       0.81      0.89      0.85     18349\n",
      "\n",
      "    accuracy                           0.74     25413\n",
      "   macro avg       0.47      0.39      0.40     25413\n",
      "weighted avg       0.71      0.74      0.72     25413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, predicted_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbee0b8-760d-47c0-b0bf-aefad82518de",
   "metadata": {},
   "source": [
    "# Google 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24c4781a-a5e7-4aa8-83ab-6d18a88ecaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmodel = load_model(\"google300-embeddings-nontrainable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694f0cf7-9a61-4e0a-ab4a-8eb5d747f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gmodel.predict([X_test_body,X_test_head])\n",
    "\n",
    "predicted_label = [LABELS[max([0, 1, 2, 3], key=lambda x: p[x])] for p in predictions]\n",
    "score = sum([pl == a for pl, a in zip(predicted_label, test_labels)])/len(test_labels)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7866f2a-68c1-4eb5-b9b1-2d268b2f3151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7313186164561445"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "477519f8-09da-4be7-ade4-2dfa97d16afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unrelated', 82.71357179396372),\n",
       " ('discuss', 11.749891787667728),\n",
       " ('agree', 4.568527918781726),\n",
       " ('disagree', 0.9680084995868257)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v*100/len(predicted_label)) for k,v in Counter(predicted_label).most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6cf3ec6-81cb-4ca3-8842-2ad487fc99cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unrelated', 73.13095333386697),\n",
       " ('discuss', 17.82798367085568),\n",
       " ('agree', 7.3601216681341555),\n",
       " ('disagree', 1.6809413271432)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v*100/len(train_labels + val_labels)) for k,v in  Counter(train_labels + val_labels).most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "267379e5-3da6-46aa-ba72-aa5587bea84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove 100               precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.27      0.16      0.20      1903\n",
      "    disagree       0.12      0.04      0.06       697\n",
      "     discuss       0.53      0.36      0.43      4464\n",
      "   unrelated       0.79      0.91      0.85     18349\n",
      "\n",
      "    accuracy                           0.73     25413\n",
      "   macro avg       0.43      0.37      0.39     25413\n",
      "weighted avg       0.69      0.73      0.70     25413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Glove 100', classification_report(test_labels, predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b26505-7daf-4959-a7f1-735e7d59b637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
